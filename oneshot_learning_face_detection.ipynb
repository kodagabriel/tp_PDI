{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "oneshot learning face detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kodagabriel/tp_PDI/blob/main/oneshot_learning_face_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUG303nnPb2t"
      },
      "source": [
        "# Instalations\n",
        "!pip install mtcnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqQEa5dblqQ-"
      },
      "source": [
        "# Imports\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from numpy import savez_compressed\n",
        "from numpy import load\n",
        "from matplotlib import pyplot\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from os.path import isdir\n",
        "from numpy import expand_dims\n",
        "from keras.models import load_model"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bkPJwweN6ho"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDLOLaBAPvi0"
      },
      "source": [
        "# extrair uma única face de um arquivo\n",
        "def extract_face(filename, required_size=(160, 160)):\n",
        "\timage = Image.open(filename)\n",
        "\t# convert to RGB, remove transparências\n",
        "\timage = image.convert('RGB')\n",
        "\tpixels = asarray(image)\n",
        "\tdetector = MTCNN()\n",
        "\t# detectar a face\n",
        "\tresults = detector.detect_faces(pixels)\n",
        "\tx1, y1, width, height = results[0]['box']\n",
        "\t# bug fix (remove valores negativos)\n",
        "\tx1, y1 = abs(x1), abs(y1)\n",
        "\tx2, y2 = x1 + width, y1 + height\n",
        "\t# seleciona a face\n",
        "\tface = pixels[y1:y2, x1:x2]\n",
        "\t# redefine o tamanho para o padrão\n",
        "\timage = Image.fromarray(face)\n",
        "\timage = image.resize(required_size)\n",
        "\tface_array = asarray(image)\n",
        "\treturn face_array\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlZqgJLiRlsb"
      },
      "source": [
        "# extrair diversas faces de uma fotografia\n",
        "def extract_faces(filename, required_size=(160, 160)):\n",
        "\timage = Image.open(filename)\n",
        "\timage = image.convert('RGB')\n",
        "\tpixels = asarray(image)\n",
        "\tdetector = MTCNN()\n",
        "\tresults = detector.detect_faces(pixels)\n",
        "\tfaces = list()\n",
        "\tfor result in results: \n",
        "\t\tx1, y1, width, height = result['box']\n",
        "\t\tx1, y1 = abs(x1), abs(y1)\n",
        "\t\tx2, y2 = x1 + width, y1 + height\n",
        "\t\tface = pixels[y1:y2, x1:x2]\n",
        "\t\timage = Image.fromarray(face)\n",
        "\t\timage = image.resize(required_size)\n",
        "\t\tface_array = asarray(image)\n",
        "\t\tfaces.append(face_array)\n",
        "\treturn asarray(faces)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGJGeo7VgYY1"
      },
      "source": [
        "# pegar todas as faces de uma pasta\n",
        "def load_faces(directory):\n",
        "\tfaces = list()\n",
        "\tfor filename in listdir(directory):\n",
        "\t\tpath = directory + filename\n",
        "\t\tface = extract_face(path)\n",
        "\t\tfaces.append(face)\n",
        "\treturn faces"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOGEUWclgsWu"
      },
      "source": [
        "# carregar database que contem várias pastas e imagens nessas pastas\n",
        "def load_dataset(directory):\n",
        "\tX, y = list(), list()\n",
        "\tfor subdir in listdir(directory):\n",
        "\t\tpath = directory + subdir + '/'\n",
        "\t\tif not isdir(path):\n",
        "\t\t\tcontinue\n",
        "\t\tfaces = load_faces(path)\n",
        "\t\tlabels = [subdir for _ in range(len(faces))]\n",
        "\t\tprint('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
        "\t\tX.extend(faces)\n",
        "\t\ty.extend(labels)\n",
        "\treturn asarray(X), asarray(y)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uwut5_HEg-so"
      },
      "source": [
        "# carregar treino\n",
        "trainX, trainy = load_dataset('/content/drive/MyDrive/PDI2/train/')\n",
        "print(trainX.shape, trainy.shape)\n",
        "# carregar teste\n",
        "testX, testy = load_dataset('/content/drive/MyDrive/PDI/test/')\n",
        "print(testX.shape, testy.shape)\n",
        "# salvar comprimido\n",
        "savez_compressed('classification-dataset.npz', trainX, trainy, testX, testy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ4MooBGnvsg"
      },
      "source": [
        "# calculo de embedding\n",
        "def get_embedding(model, face_pixels):\n",
        "\tface_pixels = face_pixels.astype('float32')\n",
        "\tmean, std = face_pixels.mean(), face_pixels.std()\n",
        "\tface_pixels = (face_pixels - mean) / std\n",
        "\tsamples = expand_dims(face_pixels, axis=0)\n",
        "\tyhat = model.predict(samples)\n",
        "\treturn yhat[0]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs3Eghr3mrds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3096d42b-1c54-4539-888b-5af613a030d7"
      },
      "source": [
        "# carregar o dataset\n",
        "data = load('classification-dataset.npz', allow_pickle=True)\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "# carrega o modelo\n",
        "model = load_model('/content/drive/MyDrive/PDI/facenet_keras.h5')\n",
        "print('Loaded Model')\n",
        "# converte as imagens de treino em embeddings\n",
        "newTrainX = list()\n",
        "for face_pixels in trainX:\n",
        "\tembedding = get_embedding(model, face_pixels)\n",
        "\tnewTrainX.append(embedding)\n",
        "newTrainX = asarray(newTrainX)\n",
        "print(newTrainX.shape)\n",
        "# convert as imagens de teste em embedding\n",
        "newTestX = list()\n",
        "for face_pixels in testX:\n",
        "\tembedding = get_embedding(model, face_pixels)\n",
        "\tnewTestX.append(embedding)\n",
        "newTestX = asarray(newTestX)\n",
        "print(newTestX.shape)\n",
        "# save arrays to one file in compressed format\n",
        "savez_compressed('classification-embeddings.npz', newTrainX, trainy, newTestX, testy)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded:  (16, 160, 160, 3) (16,) (96, 160, 160, 3) (96,)\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Loaded Model\n",
            "(16, 128)\n",
            "(96, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hPbLrPIpa9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04fe86d-2eb6-433f-c433-67ce9c19ce65"
      },
      "source": [
        "# aplicando tudo\n",
        "from numpy import load\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "# carregar embeddings\n",
        "data = load('classification-embeddings.npz')\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))\n",
        "\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "trainX = in_encoder.transform(trainX)\n",
        "testX = in_encoder.transform(testX)\n",
        "\n",
        "out_encoder = LabelEncoder()\n",
        "out_encoder.fit(trainy)\n",
        "trainy = out_encoder.transform(trainy)\n",
        "testy = out_encoder.transform(testy)\n",
        "# treinar modelo\n",
        "model = SVC(kernel='linear', probability=True)\n",
        "model.fit(trainX, trainy)\n",
        "# predizer\n",
        "yhat_train = model.predict(trainX)\n",
        "yhat_test = model.predict(testX)\n",
        "# calculos\n",
        "score_train = accuracy_score(trainy, yhat_train)\n",
        "score_test = accuracy_score(testy, yhat_test)\n",
        "\n",
        "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: train=16, test=96\n",
            "Accuracy: train=100.000, test=96.875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYjHJ0q6T4HR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ace20e98-f5c1-44e5-9f9c-d3096ee28e07"
      },
      "source": [
        "# teste com foto de sala de aula\n",
        "from random import choice\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "from matplotlib import pyplot\n",
        "# carrega as faces\n",
        "data = load('classification-dataset.npz')\n",
        "testX_faces = data['arr_2']\n",
        "# carrega os embeddings\n",
        "data = load('classification-embeddings.npz')\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "trainX = in_encoder.transform(trainX)\n",
        "testX = in_encoder.transform(testX)\n",
        "\n",
        "out_encoder = LabelEncoder()\n",
        "out_encoder.fit(trainy)\n",
        "trainy = out_encoder.transform(trainy)\n",
        "testy = out_encoder.transform(testy)\n",
        "# treino\n",
        "model = SVC(kernel='linear', probability=True)\n",
        "model.fit(trainX, trainy)\n",
        "\n",
        "# definição de resultado esperado\n",
        "class_faces = extract_faces('/content/drive/MyDrive/PDI/classroom/class1.jpg')\n",
        "class1ExpectedResult = {\n",
        "    \"ant_man\": True,\n",
        "    \"capitao_america\": True,\n",
        "    \"drax\": True,\n",
        "    \"falcao\": True,\n",
        "    \"gamora\": True,\n",
        "    \"gaviao_arqueiro\": True,\n",
        "    \"homem_aranha\": True,\n",
        "    \"hulk\": True,\n",
        "    \"ironman\": True,\n",
        "    \"pantera_negra\": True,\n",
        "    \"star_lord\": True,\n",
        "    \"strange\": True,\n",
        "    \"thor\": True,\n",
        "    \"viuva_negra\": True,\n",
        "    \"wanda\": True,\n",
        "    \"war_machine\": True\n",
        "}\n",
        "# prep para onde serão salvos os resultados encontrados\n",
        "class1Results = {\n",
        "    \"ant_man\": False,\n",
        "    \"capitao_america\": False,\n",
        "    \"drax\": False,\n",
        "    \"falcao\": False,\n",
        "    \"gamora\": False,\n",
        "    \"gaviao_arqueiro\": False,\n",
        "    \"homem_aranha\": False,\n",
        "    \"hulk\": False,\n",
        "    \"ironman\": False,\n",
        "    \"pantera_negra\": False,\n",
        "    \"star_lord\": False,\n",
        "    \"strange\": False,\n",
        "    \"thor\": False,\n",
        "    \"viuva_negra\": False,\n",
        "    \"wanda\": False,\n",
        "    \"war_machine\": False\n",
        "}\n",
        "classroom = list()\n",
        "\n",
        "model2 = load_model('/content/drive/MyDrive/PDI/facenet_keras.h5')\n",
        "for face_pixels in class_faces:\n",
        "\tprint(face_pixels.shape)\n",
        "\tembedding = get_embedding(model2, face_pixels)\n",
        "\tclassroom.append(embedding)\n",
        " \n",
        "classroom = asarray(classroom)\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "faces = in_encoder.transform(classroom)\n",
        "cont = 0\n",
        "for face in faces:\n",
        "  samples = expand_dims(face, axis=0)\n",
        "  yhat_class = model.predict(samples)\n",
        "  yhat_prob = model.predict_proba(samples)\n",
        "  class_index = yhat_class[0]\n",
        "  class_probability = yhat_prob[0,class_index] * 100\n",
        "  predict_names = out_encoder.inverse_transform(yhat_class)\n",
        "  title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
        "  class1Results[predict_names[0]] = True\n",
        "  cont += 1\n",
        "print (class1ExpectedResult)\n",
        "print (class1Results)\n",
        "total = len(class1ExpectedResult)\n",
        "corrects = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "for key in class1ExpectedResult:\n",
        "  if class1Results[key] == class1ExpectedResult[key]: \n",
        "    corrects += 1\n",
        "  elif class1Results[key] == True:\n",
        "      false_positives += 1\n",
        "  else: \n",
        "      false_negatives += 1 \n",
        "\n",
        "print(\"Acertou %.3f\" % (corrects/total * 100))\n",
        "print(\"Falsos positivos %.3f\" % (false_positives/total * 100))\n",
        "print(\"Falsos negativos %.3f\" % (false_negatives/total * 100))\n",
        "\n",
        "print(\"Total %f\" % (sum(class1ExpectedResult.values())))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "{'ant_man': True, 'capitao_america': True, 'drax': True, 'falcao': True, 'gamora': True, 'gaviao_arqueiro': True, 'homem_aranha': True, 'hulk': True, 'ironman': True, 'pantera_negra': True, 'star_lord': True, 'strange': True, 'thor': True, 'viuva_negra': True, 'wanda': True, 'war_machine': True}\n",
            "{'ant_man': True, 'capitao_america': True, 'drax': True, 'falcao': True, 'gamora': True, 'gaviao_arqueiro': True, 'homem_aranha': False, 'hulk': True, 'ironman': True, 'pantera_negra': True, 'star_lord': True, 'strange': True, 'thor': True, 'viuva_negra': True, 'wanda': True, 'war_machine': True}\n",
            "Acertou 93.750\n",
            "Falsos positivos 0.000\n",
            "Falsos negativos 6.250\n",
            "Total 16.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdwPx8x7IA4U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83997c08-b275-4d22-d04b-bc70ec7baaec"
      },
      "source": [
        "# teste sala 2\n",
        "from random import choice\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "from matplotlib import pyplot\n",
        "\n",
        "data = load('classification-dataset.npz')\n",
        "testX_faces = data['arr_2']\n",
        "\n",
        "data = load('classification-embeddings.npz')\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "trainX = in_encoder.transform(trainX)\n",
        "testX = in_encoder.transform(testX)\n",
        "\n",
        "out_encoder = LabelEncoder()\n",
        "out_encoder.fit(trainy)\n",
        "trainy = out_encoder.transform(trainy)\n",
        "testy = out_encoder.transform(testy)\n",
        "\n",
        "model = SVC(kernel='linear', probability=True)\n",
        "model.fit(trainX, trainy)\n",
        "\n",
        "\n",
        "class_faces = extract_faces('/content/drive/MyDrive/PDI/classroom/class2.jpeg')\n",
        "class1ExpectedResult = {\n",
        "    \"ant_man\": False,\n",
        "    \"capitao_america\": True,\n",
        "    \"drax\": False,\n",
        "    \"falcao\": False,\n",
        "    \"gamora\": False,\n",
        "    \"gaviao_arqueiro\": True,\n",
        "    \"homem_aranha\": False,\n",
        "    \"hulk\": False,\n",
        "    \"ironman\": True,\n",
        "    \"pantera_negra\": False,\n",
        "    \"star_lord\": False,\n",
        "    \"strange\": False,\n",
        "    \"thor\": True,\n",
        "    \"viuva_negra\": True,\n",
        "    \"wanda\": False,\n",
        "    \"war_machine\": False\n",
        "}\n",
        "\n",
        "class1Results = {\n",
        "    \"ant_man\": False,\n",
        "    \"capitao_america\": False,\n",
        "    \"drax\": False,\n",
        "    \"falcao\": False,\n",
        "    \"gamora\": False,\n",
        "    \"gaviao_arqueiro\": False,\n",
        "    \"homem_aranha\": False,\n",
        "    \"hulk\": False,\n",
        "    \"ironman\": False,\n",
        "    \"pantera_negra\": False,\n",
        "    \"star_lord\": False,\n",
        "    \"strange\": False,\n",
        "    \"thor\": False,\n",
        "    \"viuva_negra\": False,\n",
        "    \"wanda\": False,\n",
        "    \"war_machine\": False\n",
        "}\n",
        "classroom = list()\n",
        "\n",
        "model2 = load_model('/content/drive/MyDrive/PDI/facenet_keras.h5')\n",
        "for face_pixels in class_faces:\n",
        "\tprint(face_pixels.shape)\n",
        "\tembedding = get_embedding(model2, face_pixels)\n",
        "\tclassroom.append(embedding)\n",
        " \n",
        "classroom = asarray(classroom)\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "faces = in_encoder.transform(classroom)\n",
        "cont = 0\n",
        "for face in faces:\n",
        "\n",
        "  samples = expand_dims(face, axis=0)\n",
        "  yhat_class = model.predict(samples)\n",
        "  yhat_prob = model.predict_proba(samples)\n",
        "  class_index = yhat_class[0]\n",
        "  class_probability = yhat_prob[0,class_index] * 100\n",
        "  predict_names = out_encoder.inverse_transform(yhat_class)\n",
        "  title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
        "  class1Results[predict_names[0]] = True\n",
        "  cont += 1\n",
        "print (class1ExpectedResult)\n",
        "print (class1Results)\n",
        "total = len(class1ExpectedResult)\n",
        "corrects = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "for key in class1ExpectedResult:\n",
        "  if class1Results[key] == class1ExpectedResult[key]: \n",
        "    corrects += 1\n",
        "  elif class1Results[key] == True:\n",
        "      false_positives += 1\n",
        "  else: \n",
        "      false_negatives += 1 \n",
        "\n",
        "print(\"Acertou %.3f\" % (corrects/total * 100))\n",
        "print(\"Falsos positivos %.3f\" % (false_positives/total * 100))\n",
        "print(\"Falsos negativos %.3f\" % (false_negatives/total * 100))\n",
        "\n",
        "print(\"Total %f\" % (sum(class1ExpectedResult.values())))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "{'ant_man': False, 'capitao_america': True, 'drax': False, 'falcao': False, 'gamora': False, 'gaviao_arqueiro': True, 'homem_aranha': False, 'hulk': False, 'ironman': True, 'pantera_negra': False, 'star_lord': False, 'strange': False, 'thor': True, 'viuva_negra': True, 'wanda': False, 'war_machine': False}\n",
            "{'ant_man': False, 'capitao_america': True, 'drax': False, 'falcao': False, 'gamora': False, 'gaviao_arqueiro': True, 'homem_aranha': False, 'hulk': False, 'ironman': True, 'pantera_negra': False, 'star_lord': False, 'strange': False, 'thor': True, 'viuva_negra': True, 'wanda': False, 'war_machine': False}\n",
            "Acertou 100.000\n",
            "Falsos positivos 0.000\n",
            "Falsos negativos 0.000\n",
            "Total 5.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNaZRosyMEwT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "704dc73c-62b0-43f4-990d-d3ec582262f5"
      },
      "source": [
        "\n",
        "from random import choice\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "from matplotlib import pyplot\n",
        "\n",
        "data = load('classification-dataset.npz')\n",
        "testX_faces = data['arr_2']\n",
        "\n",
        "data = load('classification-embeddings.npz')\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "trainX = in_encoder.transform(trainX)\n",
        "testX = in_encoder.transform(testX)\n",
        "\n",
        "out_encoder = LabelEncoder()\n",
        "out_encoder.fit(trainy)\n",
        "trainy = out_encoder.transform(trainy)\n",
        "testy = out_encoder.transform(testy)\n",
        "\n",
        "model = SVC(kernel='linear', probability=True)\n",
        "model.fit(trainX, trainy)\n",
        "\n",
        "\n",
        "class_faces = extract_faces('/content/drive/MyDrive/PDI/classroom/class3.jpeg')\n",
        "class1ExpectedResult = {\n",
        "    \"ant_man\": False,\n",
        "    \"capitao_america\": True,\n",
        "    \"drax\": False,\n",
        "    \"falcao\": False,\n",
        "    \"gamora\": False,\n",
        "    \"gaviao_arqueiro\": True,\n",
        "    \"homem_aranha\": False,\n",
        "    \"hulk\": True,\n",
        "    \"ironman\": True,\n",
        "    \"pantera_negra\": False,\n",
        "    \"star_lord\": False,\n",
        "    \"strange\": False,\n",
        "    \"thor\": True,\n",
        "    \"viuva_negra\": True,\n",
        "    \"wanda\": False,\n",
        "    \"war_machine\": False\n",
        "}\n",
        "\n",
        "class1Results = {\n",
        "    \"ant_man\": False,\n",
        "    \"capitao_america\": False,\n",
        "    \"drax\": False,\n",
        "    \"falcao\": False,\n",
        "    \"gamora\": False,\n",
        "    \"gaviao_arqueiro\": False,\n",
        "    \"homem_aranha\": False,\n",
        "    \"hulk\": False,\n",
        "    \"ironman\": False,\n",
        "    \"pantera_negra\": False,\n",
        "    \"star_lord\": False,\n",
        "    \"strange\": False,\n",
        "    \"thor\": False,\n",
        "    \"viuva_negra\": False,\n",
        "    \"wanda\": False,\n",
        "    \"war_machine\": False\n",
        "}\n",
        "classroom = list()\n",
        "\n",
        "model2 = load_model('/content/drive/MyDrive/PDI/facenet_keras.h5')\n",
        "for face_pixels in class_faces:\n",
        "\tprint(face_pixels.shape)\n",
        "\tembedding = get_embedding(model2, face_pixels)\n",
        "\tclassroom.append(embedding)\n",
        " \n",
        "classroom = asarray(classroom)\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "faces = in_encoder.transform(classroom)\n",
        "cont = 0\n",
        "for face in faces:\n",
        "\n",
        "  samples = expand_dims(face, axis=0)\n",
        "  yhat_class = model.predict(samples)\n",
        "  yhat_prob = model.predict_proba(samples)\n",
        "  \n",
        "  class_index = yhat_class[0]\n",
        "  class_probability = yhat_prob[0,class_index] * 100\n",
        "  predict_names = out_encoder.inverse_transform(yhat_class)\n",
        "  \n",
        "  title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
        "  class1Results[predict_names[0]] = True\n",
        "  cont += 1\n",
        "print (class1ExpectedResult)\n",
        "print (class1Results)\n",
        "total = len(class1ExpectedResult)\n",
        "corrects = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "for key in class1ExpectedResult:\n",
        "  if class1Results[key] == class1ExpectedResult[key]: \n",
        "    corrects += 1\n",
        "  elif class1Results[key] == True:\n",
        "      false_positives += 1\n",
        "  else: \n",
        "      false_negatives += 1 \n",
        "\n",
        "print(\"Acertou %.3f\" % (corrects/total * 100))\n",
        "print(\"Falsos positivos %.3f\" % (false_positives/total * 100))\n",
        "print(\"Falsos negativos %.3f\" % (false_negatives/total * 100))\n",
        "\n",
        "print(\"Total %f\" % (sum(class1ExpectedResult.values())))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 20 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7449e3d9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 21 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7449e3d9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f744c8d38c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "{'ant_man': False, 'capitao_america': True, 'drax': False, 'falcao': False, 'gamora': False, 'gaviao_arqueiro': True, 'homem_aranha': False, 'hulk': True, 'ironman': True, 'pantera_negra': False, 'star_lord': False, 'strange': False, 'thor': True, 'viuva_negra': True, 'wanda': False, 'war_machine': False}\n",
            "{'ant_man': True, 'capitao_america': True, 'drax': False, 'falcao': False, 'gamora': False, 'gaviao_arqueiro': True, 'homem_aranha': False, 'hulk': True, 'ironman': True, 'pantera_negra': False, 'star_lord': False, 'strange': False, 'thor': True, 'viuva_negra': True, 'wanda': True, 'war_machine': False}\n",
            "Acertou 87.500\n",
            "Falsos positivos 12.500\n",
            "Falsos negativos 0.000\n",
            "Total 6.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX_Q7gLHNQ3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5293c71e-bd86-4995-a82c-dc489ce81db8"
      },
      "source": [
        "\n",
        "from random import choice\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "from matplotlib import pyplot\n",
        "\n",
        "data = load('classification-dataset.npz')\n",
        "testX_faces = data['arr_2']\n",
        "\n",
        "data = load('classification-embeddings.npz')\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "trainX = in_encoder.transform(trainX)\n",
        "testX = in_encoder.transform(testX)\n",
        "\n",
        "out_encoder = LabelEncoder()\n",
        "out_encoder.fit(trainy)\n",
        "trainy = out_encoder.transform(trainy)\n",
        "testy = out_encoder.transform(testy)\n",
        "\n",
        "model = SVC(kernel='linear', probability=True)\n",
        "model.fit(trainX, trainy)\n",
        "\n",
        "\n",
        "class_faces = extract_faces('/content/drive/MyDrive/PDI/classroom/class4.jpeg')\n",
        "class1ExpectedResult = {\n",
        "    \"ant_man\": False,\n",
        "    \"capitao_america\": True,\n",
        "    \"drax\": False,\n",
        "    \"falcao\": False,\n",
        "    \"gamora\": False,\n",
        "    \"gaviao_arqueiro\": True,\n",
        "    \"homem_aranha\": False,\n",
        "    \"hulk\": True,\n",
        "    \"ironman\": False,\n",
        "    \"pantera_negra\": False,\n",
        "    \"star_lord\": False,\n",
        "    \"strange\": False,\n",
        "    \"thor\": True,\n",
        "    \"viuva_negra\": True,\n",
        "    \"wanda\": False,\n",
        "    \"war_machine\": False\n",
        "}\n",
        "\n",
        "class1Results = {\n",
        "    \"ant_man\": False,\n",
        "    \"capitao_america\": False,\n",
        "    \"drax\": False,\n",
        "    \"falcao\": False,\n",
        "    \"gamora\": False,\n",
        "    \"gaviao_arqueiro\": False,\n",
        "    \"homem_aranha\": False,\n",
        "    \"hulk\": False,\n",
        "    \"ironman\": False,\n",
        "    \"pantera_negra\": False,\n",
        "    \"star_lord\": False,\n",
        "    \"strange\": False,\n",
        "    \"thor\": False,\n",
        "    \"viuva_negra\": False,\n",
        "    \"wanda\": False,\n",
        "    \"war_machine\": False\n",
        "}\n",
        "classroom = list()\n",
        "\n",
        "model2 = load_model('/content/drive/MyDrive/PDI/facenet_keras.h5')\n",
        "for face_pixels in class_faces:\n",
        "\tprint(face_pixels.shape)\n",
        "\tembedding = get_embedding(model2, face_pixels)\n",
        "\tclassroom.append(embedding)\n",
        " \n",
        "classroom = asarray(classroom)\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "faces = in_encoder.transform(classroom)\n",
        "cont = 0\n",
        "for face in faces:\n",
        "  \n",
        "  samples = expand_dims(face, axis=0)\n",
        "  yhat_class = model.predict(samples)\n",
        "  yhat_prob = model.predict_proba(samples)\n",
        "  \n",
        "  class_index = yhat_class[0]\n",
        "  class_probability = yhat_prob[0,class_index] * 100\n",
        "  predict_names = out_encoder.inverse_transform(yhat_class)\n",
        "  \n",
        "  title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
        "  class1Results[predict_names[0]] = True\n",
        "  cont += 1\n",
        "print (class1ExpectedResult)\n",
        "print (class1Results)\n",
        "total = len(class1ExpectedResult)\n",
        "corrects = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "for key in class1ExpectedResult:\n",
        "  if class1Results[key] == class1ExpectedResult[key]: \n",
        "    corrects += 1\n",
        "  elif class1Results[key] == True:\n",
        "      false_positives += 1\n",
        "  else: \n",
        "      false_negatives += 1 \n",
        "\n",
        "print(\"Acertou %.3f\" % (corrects/total * 100))\n",
        "print(\"Falsos positivos %.3f\" % (false_positives/total * 100))\n",
        "print(\"Falsos negativos %.3f\" % (false_negatives/total * 100))\n",
        "\n",
        "print(\"Total %f\" % (sum(class1ExpectedResult.values())))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "{'ant_man': False, 'capitao_america': True, 'drax': False, 'falcao': False, 'gamora': False, 'gaviao_arqueiro': True, 'homem_aranha': False, 'hulk': True, 'ironman': False, 'pantera_negra': False, 'star_lord': False, 'strange': False, 'thor': True, 'viuva_negra': True, 'wanda': False, 'war_machine': False}\n",
            "{'ant_man': False, 'capitao_america': True, 'drax': False, 'falcao': False, 'gamora': False, 'gaviao_arqueiro': True, 'homem_aranha': True, 'hulk': True, 'ironman': False, 'pantera_negra': False, 'star_lord': False, 'strange': False, 'thor': False, 'viuva_negra': False, 'wanda': True, 'war_machine': False}\n",
            "Acertou 75.000\n",
            "Falsos positivos 12.500\n",
            "Falsos negativos 12.500\n",
            "Total 5.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u2JypIGNQwI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48aae89-0f41-45a1-d42d-59bef2ff94e1"
      },
      "source": [
        "\n",
        "from random import choice\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "from matplotlib import pyplot\n",
        "\n",
        "data = load('classification-dataset.npz')\n",
        "testX_faces = data['arr_2']\n",
        "\n",
        "data = load('classification-embeddings.npz')\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "trainX = in_encoder.transform(trainX)\n",
        "testX = in_encoder.transform(testX)\n",
        "\n",
        "out_encoder = LabelEncoder()\n",
        "out_encoder.fit(trainy)\n",
        "trainy = out_encoder.transform(trainy)\n",
        "testy = out_encoder.transform(testy)\n",
        "\n",
        "model = SVC(kernel='linear', probability=True)\n",
        "model.fit(trainX, trainy)\n",
        "\n",
        "\n",
        "class_faces = extract_faces('/content/drive/MyDrive/PDI/classroom/class5.jpg')\n",
        "class1ExpectedResult = {\n",
        "    \"ant_man\": False,\n",
        "    \"capitao_america\": True,\n",
        "    \"drax\": True,\n",
        "    \"falcao\": False,\n",
        "    \"gamora\": True,\n",
        "    \"gaviao_arqueiro\": True,\n",
        "    \"homem_aranha\": False,\n",
        "    \"hulk\": True,\n",
        "    \"ironman\": True,\n",
        "    \"pantera_negra\": True,\n",
        "    \"star_lord\": True,\n",
        "    \"strange\": False,\n",
        "    \"thor\": True,\n",
        "    \"viuva_negra\": True,\n",
        "    \"wanda\": False,\n",
        "    \"war_machine\": False\n",
        "}\n",
        "\n",
        "class1Results = {\n",
        "    \"ant_man\": False,\n",
        "    \"capitao_america\": False,\n",
        "    \"drax\": False,\n",
        "    \"falcao\": False,\n",
        "    \"gamora\": False,\n",
        "    \"gaviao_arqueiro\": False,\n",
        "    \"homem_aranha\": False,\n",
        "    \"hulk\": False,\n",
        "    \"ironman\": False,\n",
        "    \"pantera_negra\": False,\n",
        "    \"star_lord\": False,\n",
        "    \"strange\": False,\n",
        "    \"thor\": False,\n",
        "    \"viuva_negra\": False,\n",
        "    \"wanda\": False,\n",
        "    \"war_machine\": False\n",
        "}\n",
        "classroom = list()\n",
        "\n",
        "model2 = load_model('/content/drive/MyDrive/PDI/facenet_keras.h5')\n",
        "for face_pixels in class_faces:\n",
        "\tprint(face_pixels.shape)\n",
        "\tembedding = get_embedding(model2, face_pixels)\n",
        "\tclassroom.append(embedding)\n",
        " \n",
        "classroom = asarray(classroom)\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "faces = in_encoder.transform(classroom)\n",
        "cont = 0\n",
        "for face in faces:\n",
        "  \n",
        "  samples = expand_dims(face, axis=0)\n",
        "  yhat_class = model.predict(samples)\n",
        "  yhat_prob = model.predict_proba(samples)\n",
        " \n",
        "  class_index = yhat_class[0]\n",
        "  class_probability = yhat_prob[0,class_index] * 100\n",
        "  predict_names = out_encoder.inverse_transform(yhat_class)\n",
        "  \n",
        "  title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
        "  class1Results[predict_names[0]] = True\n",
        "  cont += 1\n",
        "print (class1ExpectedResult)\n",
        "print (class1Results)\n",
        "total = len(class1ExpectedResult)\n",
        "corrects = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "for key in class1ExpectedResult:\n",
        "  if class1Results[key] == class1ExpectedResult[key]: \n",
        "    corrects += 1\n",
        "  elif class1Results[key] == True:\n",
        "      false_positives += 1\n",
        "  else: \n",
        "      false_negatives += 1 \n",
        "\n",
        "print(\"Acertou %.3f\" % (corrects/total * 100))\n",
        "print(\"Falsos positivos %.3f\" % (false_positives/total * 100))\n",
        "print(\"Falsos negativos %.3f\" % (false_negatives/total * 100))\n",
        "\n",
        "print(\"Total %f\" % (sum(class1ExpectedResult.values())))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7449e9a830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "(160, 160, 3)\n",
            "{'ant_man': False, 'capitao_america': True, 'drax': True, 'falcao': False, 'gamora': True, 'gaviao_arqueiro': True, 'homem_aranha': False, 'hulk': True, 'ironman': True, 'pantera_negra': True, 'star_lord': True, 'strange': False, 'thor': True, 'viuva_negra': True, 'wanda': False, 'war_machine': False}\n",
            "{'ant_man': False, 'capitao_america': True, 'drax': False, 'falcao': False, 'gamora': False, 'gaviao_arqueiro': True, 'homem_aranha': False, 'hulk': True, 'ironman': True, 'pantera_negra': False, 'star_lord': True, 'strange': True, 'thor': True, 'viuva_negra': False, 'wanda': False, 'war_machine': False}\n",
            "Acertou 68.750\n",
            "Falsos positivos 6.250\n",
            "Falsos negativos 25.000\n",
            "Total 10.000000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}